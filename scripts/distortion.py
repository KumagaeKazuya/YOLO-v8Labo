import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import time
from ultralytics import YOLO
from collections import defaultdict, deque
import logging
import csv
from datetime import datetime

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

class EnhancedCSVLogger:
    """æ©Ÿæ¢°å­¦ç¿’ç”¨æ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼"""

    def __init__(self, csv_path="enhanced_detection_log.csv"):
        self.csv_path = csv_path
        self.csv_file = None
        self.csv_writer = None
        self.start_time = time.time()
        self.prev_keypoints = {}  # track_id -> previous keypoints for motion calculation
        self.log_count = 0

        # CSV ãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾©
        self.headers = [
            # åŸºæœ¬æƒ…å ±
            "timestamp", "frame_idx", "relative_time_sec", "frame_interval_ms",

            # äººç‰©è­˜åˆ¥æƒ…å ±
            "person_id", "track_confidence", "detection_confidence",

            # ä½ç½®æƒ…å ±
            "bbox_x1", "bbox_y1", "bbox_x2", "bbox_y2",
            "bbox_width", "bbox_height", "bbox_area",
            "center_x", "center_y", "grid_row", "grid_col",

            # è¡Œå‹•åˆ¤å®š
            "using_phone", "phone_detection_confidence", "smoothed_phone_usage",
            "phone_detection_method",  # "front_view", "back_view", "failed"

            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåº§æ¨™ (17ç‚¹ x 3åº§æ¨™ = 51åˆ—)
            *[f"kp_{i}_{coord}" for i in range(17) for coord in ["x", "y", "conf"]],

            # å‹•ä½œç‰¹å¾´é‡
            "movement_speed_px_per_frame", "pose_change_magnitude",
            "head_movement_speed", "hand_movement_speed",
            "wrist_to_face_dist_left", "wrist_to_face_dist_right", "min_wrist_face_dist",

            # å§¿å‹¢åˆ†æ
            "head_pose_angle", "shoulder_width", "torso_lean_angle",
            "left_arm_angle", "right_arm_angle",

            # ç”»åƒå“è³ªãƒ»ç’°å¢ƒè¦å› 
            "frame_brightness", "frame_contrast", "blur_score", "noise_level",

            # æ™‚ç³»åˆ—ç‰¹å¾´
            "consecutive_phone_frames", "phone_state_duration_sec",
            "position_stability", "tracking_quality",

            # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨
            "manual_label_phone", "manual_label_posture", "manual_label_attention",
            "annotation_confidence", "annotator_id", "review_required",

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            "video_source", "processing_version", "model_version", "notes"
        ]

        self.init_csv()

    def init_csv(self):
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸåŒ–"""
        try:
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            os.makedirs(os.path.dirname(self.csv_path), exist_ok=True)

            self.csv_file = open(self.csv_path, 'w', newline='', encoding='utf-8')
            self.csv_writer = csv.writer(self.csv_file)
            self.csv_writer.writerow(self.headers)

            # å³åº§ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã—ã¦ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›¸ãè¾¼ã¿
            self.csv_file.flush()

            logger.info(f"æ‹¡å¼µCSVãƒ­ã‚°ã‚’åˆæœŸåŒ–: {self.csv_path}")
            logger.info(f"CSVãƒ˜ãƒƒãƒ€ãƒ¼: {self.headers}")

        except Exception as e:
            logger.error(f"CSVåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def safe_keypoint_access(self, keypoints, index, coord_index=None):
        """å®‰å…¨ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚¢ã‚¯ã‚»ã‚¹ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            if index >= len(keypoints):
                return 0.0

            kp = keypoints[index]

            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®å½¢çŠ¶ã‚’ãƒã‚§ãƒƒã‚¯
            if len(kp.shape) > 1:
                # 2Dé…åˆ—ã®å ´åˆã¯æœ€åˆã®è¡Œã‚’ä½¿ç”¨
                kp = kp[0] if kp.shape[0] > 0 else np.array([0, 0])

            if coord_index is None:
                # å…¨ä½“ã‚’è¿”ã™å ´åˆ
                if len(kp) >= 3:
                    return kp[:3]  # [x, y, conf]
                elif len(kp) >= 2:
                    return np.array([kp[0], kp[1], 0.0])  # conf=0.0ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                else:
                    return np.array([0.0, 0.0, 0.0])
            else:
                # ç‰¹å®šã®åº§æ¨™ã‚’è¿”ã™å ´åˆ
                if coord_index < len(kp):
                    return float(kp[coord_index])
                elif coord_index == 2:  # confidence
                    return 0.0  # confidenceãŒãªã„å ´åˆã¯0.0
                else:
                    return 0.0

        except Exception as e:
            logger.warning(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ (index={index}, coord={coord_index}): {e}")
            if coord_index is None:
                return np.array([0.0, 0.0, 0.0])
            else:
                return 0.0

    def calculate_keypoint_features(self, keypoints, track_id):
        """ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆç°¡ç´ åŒ–ç‰ˆï¼‰"""
        features = {
            'wrist_to_face_dist_left': -1,
            'wrist_to_face_dist_right': -1,
            'min_wrist_face_dist': -1,
            'shoulder_width': -1,
            'movement_speed_px_per_frame': 0,
            'pose_change_magnitude': 0,
            'head_movement_speed': 0,
            'hand_movement_speed': 0,
            'head_pose_angle': 0,
            'torso_lean_angle': 0,
            'left_arm_angle': 0,
            'right_arm_angle': 0
        }

        try:
            # åŸºæœ¬çš„ãªè·é›¢è¨ˆç®—ã®ã¿å®Ÿè£…
            if len(keypoints) >= 17:
                # å®‰å…¨ã«ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
                nose = self.safe_keypoint_access(keypoints, 0)
                left_wrist = self.safe_keypoint_access(keypoints, 9)
                right_wrist = self.safe_keypoint_access(keypoints, 10)
                left_shoulder = self.safe_keypoint_access(keypoints, 5)
                right_shoulder = self.safe_keypoint_access(keypoints, 6)

                # æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆconfidence > 0.3 ã¾ãŸã¯ x,y > 0ï¼‰
                def is_valid_point(pt):
                    if len(pt) >= 3:
                        return pt[2] > 0.3 and pt[0] > 0 and pt[1] > 0
                    else:
                        return pt[0] > 0 and pt[1] > 0

                # æ‰‹é¦–-é¡”ã®è·é›¢
                if is_valid_point(nose) and is_valid_point(left_wrist):
                    features['wrist_to_face_dist_left'] = float(np.linalg.norm(nose[:2] - left_wrist[:2]))

                if is_valid_point(nose) and is_valid_point(right_wrist):
                    features['wrist_to_face_dist_right'] = float(np.linalg.norm(nose[:2] - right_wrist[:2]))

                # æœ€å°è·é›¢
                valid_dists = [d for d in [features['wrist_to_face_dist_left'], 
                                        features['wrist_to_face_dist_right']] if d > 0]
                if valid_dists:
                    features['min_wrist_face_dist'] = min(valid_dists)

                # è‚©å¹…
                if is_valid_point(left_shoulder) and is_valid_point(right_shoulder):
                    features['shoulder_width'] = float(np.linalg.norm(left_shoulder[:2] - right_shoulder[:2]))

        except Exception as e:
            logger.warning(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")

        return features


    def calculate_image_quality(self, frame, bbox):
        """ç”»åƒå“è³ªæŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆç°¡ç´ åŒ–ç‰ˆï¼‰"""
        try:
            x1, y1, x2, y2 = map(int, bbox)
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)

            if x2 <= x1 or y2 <= y1:
                return {'brightness': 0, 'contrast': 0, 'blur_score': 0, 'noise_level': 0}

            roi = frame[y1:y2, x1:x2]

            if roi.size == 0:
                return {'brightness': 0, 'contrast': 0, 'blur_score': 0, 'noise_level': 0}

            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
            gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape) > 2 else roi

            # åŸºæœ¬çš„ãªå“è³ªæŒ‡æ¨™
            brightness = float(np.mean(gray_roi))
            contrast = float(np.std(gray_roi))
            blur_score = float(cv2.Laplacian(gray_roi, cv2.CV_64F).var())
            noise_level = 0.0  # ç°¡ç´ åŒ–

            return {
                'brightness': brightness,
                'contrast': contrast,
                'blur_score': blur_score,
                'noise_level': noise_level
            }

        except Exception as e:
            logger.warning(f"ç”»åƒå“è³ªè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'brightness': 0, 'contrast': 0, 'blur_score': 0, 'noise_level': 0}

    def log_detection(self, frame_idx, track_id, detection_data, frame,
                    phone_usage, phone_confidence, phone_method,
                    grid_row, grid_col, video_source="unknown"):
        """æ‹¡å¼µæ¤œå‡ºãƒ­ã‚°ã‚’è¨˜éŒ²ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            self.log_count += 1

            current_time = time.time()
            timestamp = datetime.now().isoformat()
            relative_time = current_time - self.start_time

            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—
            keypoints = detection_data['keypoints']
            bbox = detection_data['bbox']
            center = detection_data['center']
            confidence = detection_data.get('confidence', 0.0)

            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æƒ…å ±
            x1, y1, x2, y2 = bbox
            bbox_width = x2 - x1
            bbox_height = y2 - y1
            bbox_area = bbox_width * bbox_height

            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆç‰¹å¾´é‡è¨ˆç®—
            kp_features = self.calculate_keypoint_features(keypoints, track_id)

            # ç”»åƒå“è³ªè¨ˆç®—
            quality_metrics = self.calculate_image_quality(frame, bbox)

            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåº§æ¨™ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ï¼ˆ17ç‚¹Ã—3åº§æ¨™=51åˆ—ï¼‰- ä¿®æ­£ç‰ˆ
            kp_coords = []
            for i in range(17):
                if i < len(keypoints):
                    # å®‰å…¨ã«ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹
                    x = self.safe_keypoint_access(keypoints, i, 0)
                    y = self.safe_keypoint_access(keypoints, i, 1)
                    conf = self.safe_keypoint_access(keypoints, i, 2)
                    kp_coords.extend([float(x), float(y), float(conf)])
                else:
                    kp_coords.extend([0.0, 0.0, 0.0])

            # ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿æº–å‚™
            log_data = [
                # åŸºæœ¬æƒ…å ±
                timestamp, frame_idx, relative_time, 33.33,

                # äººç‰©è­˜åˆ¥æƒ…å ±
                track_id, 0.9, float(confidence),

                # ä½ç½®æƒ…å ±
                float(x1), float(y1), float(x2), float(y2),
                float(bbox_width), float(bbox_height), float(bbox_area),
                float(center[0]), float(center[1]), grid_row, grid_col,

                # è¡Œå‹•åˆ¤å®š
                phone_usage, phone_confidence, phone_usage, phone_method,

                # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåº§æ¨™ï¼ˆ51åˆ—ï¼‰
                *kp_coords,

                # å‹•ä½œç‰¹å¾´é‡
                kp_features['movement_speed_px_per_frame'],
                kp_features['pose_change_magnitude'],
                kp_features['head_movement_speed'],
                kp_features['hand_movement_speed'],
                kp_features['wrist_to_face_dist_left'],
                kp_features['wrist_to_face_dist_right'],
                kp_features['min_wrist_face_dist'],

                # å§¿å‹¢åˆ†æ
                kp_features['head_pose_angle'],
                kp_features['shoulder_width'],
                kp_features['torso_lean_angle'],
                kp_features['left_arm_angle'],
                kp_features['right_arm_angle'],

                # ç”»åƒå“è³ª
                quality_metrics['brightness'],
                quality_metrics['contrast'],
                quality_metrics['blur_score'],
                quality_metrics['noise_level'],

                # æ™‚ç³»åˆ—ç‰¹å¾´ï¼ˆä»®å€¤ï¼‰
                0, 0.0, 0.8, 0.9,

                # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼ˆç©ºæ¬„ï¼‰
                "", "", "", 0.0, "", False,

                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                video_source, "v1.0", "yolo11m-pose", ""
            ]

            # ãƒ‡ãƒ¼ã‚¿é•·ãƒã‚§ãƒƒã‚¯
            expected_length = len(self.headers)
            actual_length = len(log_data)

            if actual_length != expected_length:
                logger.error(f"ãƒ‡ãƒ¼ã‚¿é•·ä¸ä¸€è‡´: æœŸå¾…{expected_length}, å®Ÿéš›{actual_length}")

                # ä¸è¶³åˆ†ã‚’åŸ‹ã‚ã‚‹
                while len(log_data) < expected_length:
                    log_data.append("")
                # ä½™åˆ†ã‚’å‰Šã‚‹
                log_data = log_data[:expected_length]

            # CSVæ›¸ãè¾¼ã¿
            if self.csv_writer:
                self.csv_writer.writerow(log_data)
                self.csv_file.flush()  # å³åº§ã«ãƒ‡ã‚£ã‚¹ã‚¯ã«æ›¸ãè¾¼ã¿

                # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆæœ€åˆã®æ•°å›ã®ã¿ï¼‰
                if self.log_count <= 3:
                    logger.info(f"æ‹¡å¼µCSVè¨˜éŒ² #{self.log_count}: frame={frame_idx}, person={track_id}")
                elif self.log_count % 30 == 0:  # 30å›ã”ã¨
                    logger.info(f"æ‹¡å¼µCSVè¨˜éŒ²ç¶™ç¶š: {self.log_count}è¡Œç›®")

        except Exception as e:
            logger.error(f"ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼ (frame={frame_idx}, person={track_id}): {e}")
            import traceback
            traceback.print_exc()

    def close(self):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒ­ãƒ¼ã‚º"""
        try:
            if self.csv_file:
                self.csv_file.flush()
                self.csv_file.close()
                logger.info(f"æ‹¡å¼µCSVãƒ­ã‚°ä¿å­˜å®Œäº†: {self.csv_path}")
                logger.info(f"ç·è¨˜éŒ²æ•°: {self.log_count}è¡Œ")
        except Exception as e:
            logger.error(f"CSVã‚¯ãƒ­ãƒ¼ã‚ºã‚¨ãƒ©ãƒ¼: {e}")


class VideoDistortionCorrector:
    """å‹•ç”»ã®æ­ªã¿è£œæ­£ã‚¯ãƒ©ã‚¹ï¼ˆé€†ãƒãƒ¬ãƒ«è£œæ­£ç‰ˆï¼‰"""

    def __init__(self, k1=-0.1, strength=1.0, zoom_factor=1.2):
        self.k1 = k1
        self.strength = strength
        self.zoom_factor = zoom_factor
        self.map_x = None
        self.map_y = None

    def create_correction_maps(self, width, height):
        """
        é€†ãƒãƒ¬ãƒ«æ­ªã¿è£œæ­£ã¨ã‚ºãƒ¼ãƒ èª¿æ•´ç”¨ã®ãƒãƒƒãƒ—ã‚’ä½œæˆ

        Returns:
        map_x, map_y: æ­ªã¿è£œæ­£ç”¨ã®ãƒãƒƒãƒ—
        """
        # ç”»åƒã®ä¸­å¿ƒã‚’è¨ˆç®—
        cx, cy = width // 2, height // 2
        max_radius = min(cx, cy)

        # å¤‰æ›ãƒãƒƒãƒ—ã‚’ä½œæˆ
        map_x = np.zeros((height, width), dtype=np.float32)
        map_y = np.zeros((height, width), dtype=np.float32)

        # èª¿æ•´ã•ã‚ŒãŸæ­ªã¿ä¿‚æ•°
        adjusted_k1 = self.k1 * self.strength

        # å„ãƒ”ã‚¯ã‚»ãƒ«ã®è£œæ­£ã‚’è¨ˆç®—
        for y in range(height):
            for x in range(width):
                # ä¸­å¿ƒã‹ã‚‰ã®è·é›¢
                dx = x - cx
                dy = y - cy
                r = np.sqrt(dx*dx + dy*dy)

                if r > 0:
                    # æ­£è¦åŒ–ã•ã‚ŒãŸåŠå¾„
                    r_norm = r / max_radius

                    # é€†ãƒãƒ¬ãƒ«æ­ªã¿è£œæ­£
                    r_corrected = r * (1 + adjusted_k1 * r_norm * r_norm)

                    # ã‚ºãƒ¼ãƒ èª¿æ•´ã‚’é©ç”¨
                    scale = (r_corrected / r) * self.zoom_factor
                    new_x = cx + dx * scale
                    new_y = cy + dy * scale

                    map_x[y, x] = new_x
                    map_y[y, x] = new_y
                else:
                    map_x[y, x] = x
                    map_y[y, x] = y

        self.map_x = map_x
        self.map_y = map_y

        return self.map_x, self.map_y

    def apply_correction(self, frame):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ­ªã¿è£œæ­£ã‚’é©ç”¨"""
        if self.map_x is None or self.map_y is None:
            raise ValueError("è£œæ­£ãƒãƒƒãƒ—ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚create_correction_maps()ã‚’å…ˆã«å‘¼ã³å‡ºã—ã¦ãã ã•ã„ã€‚")

        return cv2.remap(frame, self.map_x, self.map_y, cv2.INTER_LINEAR)


class OrderedIDTracker:
    """å·¦ã‹ã‚‰é †ã«IDã‚’å‰²ã‚ŠæŒ¯ã‚‹è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, distance_threshold=100, max_missing_frames=30):
        self.distance_threshold = distance_threshold
        self.max_missing_frames = max_missing_frames
        self.tracked_persons = {}  # {id: {'center': (x, y), 'missing_count': int, 'bbox': (x1,y1,x2,y2)}}
        self.next_id = 1

    def update_tracks(self, detections):
        """
        æ¤œå‡ºçµæœã‚’æ›´æ–°ã—ã€å·¦ã‹ã‚‰é †ã«IDã‚’å‰²ã‚ŠæŒ¯ã‚‹

        Parameters:
        detections: list of dict with keys: 'center', 'bbox', 'keypoints', 'confidence'

        Returns:
        list of dict with assigned IDs
        """
        if not detections:
            # æ¤œå‡ºãŒãªã„å ´åˆã€æ—¢å­˜ã®è¿½è·¡ã‚’æ›´æ–°
            self._update_missing_counts()
            return []

        # æ¤œå‡ºçµæœã‚’å·¦ã‹ã‚‰å³ã¸ã‚½ãƒ¼ãƒˆï¼ˆxåº§æ¨™é †ï¼‰
        detections_sorted = sorted(detections, key=lambda d: d['center'][0])

        # æ—¢å­˜ã®è¿½è·¡å¯¾è±¡ã‚‚å·¦ã‹ã‚‰å³ã¸ã‚½ãƒ¼ãƒˆ
        existing_tracks = sorted(self.tracked_persons.items(), key=lambda t: t[1]['center'][0])

        assigned_detections = []
        used_track_ids = set()

        # æ—¢å­˜ã®è¿½è·¡å¯¾è±¡ã¨ã®ãƒãƒƒãƒãƒ³ã‚°
        for detection in detections_sorted:
            best_match_id = None
            best_distance = float('inf')

            detection_center = detection['center']

            # æ—¢å­˜ã®è¿½è·¡å¯¾è±¡ã¨ã®è·é›¢ã‚’è¨ˆç®—
            for track_id, track_data in existing_tracks:
                if track_id in used_track_ids:
                    continue

                track_center = track_data['center']
                distance = np.linalg.norm(np.array(detection_center) - np.array(track_center))

                if distance < self.distance_threshold and distance < best_distance:
                    best_distance = distance
                    best_match_id = track_id

            # ãƒãƒƒãƒã—ãŸå ´åˆã¯æ—¢å­˜IDã‚’ä½¿ç”¨ã€ãã†ã§ãªã‘ã‚Œã°æ–°ã—ã„IDã‚’å‰²ã‚ŠæŒ¯ã‚Š
            if best_match_id is not None:
                assigned_id = best_match_id
                used_track_ids.add(assigned_id)
            else:
                assigned_id = self._get_next_available_id()

            # è¿½è·¡ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
            self.tracked_persons[assigned_id] = {
                'center': detection_center,
                'missing_count': 0,
                'bbox': detection['bbox']
            }

            # çµæœã«è¿½åŠ 
            detection_with_id = detection.copy()
            detection_with_id['track_id'] = assigned_id
            assigned_detections.append(detection_with_id)

        # ä½¿ç”¨ã•ã‚Œãªã‹ã£ãŸè¿½è·¡å¯¾è±¡ã®missing_countã‚’å¢—åŠ 
        for track_id in list(self.tracked_persons.keys()):
            if track_id not in used_track_ids:
                self.tracked_persons[track_id]['missing_count'] += 1

                # é•·æ™‚é–“è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å‰Šé™¤
                if self.tracked_persons[track_id]['missing_count'] > self.max_missing_frames:
                    del self.tracked_persons[track_id]
                    logger.debug(f"Track ID {track_id} removed due to long absence")

        return assigned_detections

    def _get_next_available_id(self):
        """æ¬¡ã«åˆ©ç”¨å¯èƒ½ãªIDã‚’å–å¾—ï¼ˆå·¦ã‹ã‚‰é †ã®é †åºã‚’ä¿ã¤ãŸã‚ï¼‰"""
        # æ—¢å­˜ã®IDã®ä¸­ã§æœ€å°ã®æ¬ ç•ªã‚’æ¢ã™
        existing_ids = set(self.tracked_persons.keys())

        # 1ã‹ã‚‰é †ç•ªã«ãƒã‚§ãƒƒã‚¯
        for i in range(1, max(existing_ids) + 2 if existing_ids else 2):
            if i not in existing_ids:
                return i

        # ã“ã“ã«åˆ°é”ã™ã‚‹ã“ã¨ã¯ãªã„ãŒã€å¿µã®ãŸã‚
        return max(existing_ids) + 1 if existing_ids else 1

    def _update_missing_counts(self):
        """å…¨ã¦ã®è¿½è·¡å¯¾è±¡ã®missing_countã‚’æ›´æ–°"""
        for track_id in list(self.tracked_persons.keys()):
            self.tracked_persons[track_id]['missing_count'] += 1
            if self.tracked_persons[track_id]['missing_count'] > self.max_missing_frames:
                del self.tracked_persons[track_id]
                logger.debug(f"Track ID {track_id} removed due to long absence")

    def get_active_tracks(self):
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªè¿½è·¡å¯¾è±¡ã‚’å–å¾—"""
        return {tid: data for tid, data in self.tracked_persons.items()}


class PostureDetectionSystem:
    """å§¿å‹¢æ¨å®šã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹ï¼ˆé †åºä»˜ãIDå‰²ã‚ŠæŒ¯ã‚Šç‰ˆï¼‰"""

    def __init__(self, model_path="models/yolo11m-pose.pt"):
        self.model = YOLO(model_path)

        # é †åºä»˜ãIDãƒˆãƒ©ãƒƒã‚«ãƒ¼ã‚’åˆæœŸåŒ–
        from scripts.distortion import OrderedIDTracker
        self.id_tracker = OrderedIDTracker(distance_threshold=100, max_missing_frames=30)

        # äººç‰©ã®çŠ¶æ…‹ç®¡ç†ï¼ˆtrack_idãƒ™ãƒ¼ã‚¹ï¼‰
        self.person_states = {}

        self.config = {
            "conf_threshold": 0.4,
            "phone_distance_threshold": 100,
            "smoothing_frames": 5,
            "detection_interval": 3,
        }

        # ã‚°ãƒªãƒƒãƒ‰åˆ†å‰²è¨­å®šã‚’åˆæœŸåŒ–
        self.split_ratios = [0.5, 0.5]  # ä¸Šä¸‹50%ãšã¤
        self.split_ratios_cols = [0.5, 0.5]  # å·¦å³50%ãšã¤

    def safe_keypoint_access(self, keypoints, index):
        """å®‰å…¨ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚¢ã‚¯ã‚»ã‚¹"""
        try:
            if index >= len(keypoints):
                return None

            kp = keypoints[index]

            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®å½¢çŠ¶ã‚’ãƒã‚§ãƒƒã‚¯
            if len(kp.shape) > 1:
                # 2Dé…åˆ—ã®å ´åˆã¯æœ€åˆã®è¡Œã‚’ä½¿ç”¨
                kp = kp[0] if kp.shape[0] > 0 else np.array([0, 0])

            # åº§æ¨™ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
            if len(kp) >= 2:
                x, y = kp[0], kp[1]
                confidence = kp[2] if len(kp) > 2 else 0.0

                if x > 0 and y > 0 and (len(kp) <= 2 or confidence > 0.3):
                    return kp[:2]  # [x, y]ã®ã¿è¿”ã™

            return None

        except Exception as e:
            logger.warning(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ (index={index}): {e}")
            return None


    def smooth_detection(self, track_id, using_phone):
        """æ¤œå‡ºçµæœã‚’å¹³æ»‘åŒ–ï¼ˆtrack_idãƒ™ãƒ¼ã‚¹ï¼‰"""
        if track_id not in self.person_states:
            self.person_states[track_id] = {
                "phone_history": deque(maxlen=self.config["smoothing_frames"]),
                "last_seen": 0,
            }

        state = self.person_states[track_id]
        state["phone_history"].append(using_phone)

        # å¹³æ»‘åŒ–ï¼šéåŠæ•°ã®åˆ¤å®šã§æ±ºå®š
        if len(state["phone_history"]) == 0:
            return False

        smoothed_phone = sum(state["phone_history"]) > len(state["phone_history"]) // 2
        return smoothed_phone

    def detect_phone_usage(self, keypoints):
        """æºå¸¯é›»è©±ä½¿ç”¨ã‚’æ¤œå‡ºï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯
            if keypoints is None or keypoints.shape[0] < 17:
                return False

            # å¿…è¦ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’å®‰å…¨ã«å–å¾—
            nose = self.safe_keypoint_access(keypoints, 0)
            left_wrist = self.safe_keypoint_access(keypoints, 9)
            right_wrist = self.safe_keypoint_access(keypoints, 10)

            # åŸºæœ¬çš„ãªæºå¸¯ä½¿ç”¨åˆ¤å®š
            if all(pt is not None for pt in [nose, left_wrist, right_wrist]):
                threshold = self.config["phone_distance_threshold"]
                dist_left = np.linalg.norm(nose - left_wrist)
                dist_right = np.linalg.norm(nose - right_wrist)

                if min(dist_left, dist_right) < threshold:
                    return True

            # èƒŒé¢åˆ¤å®šã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self.detect_phone_usage_back_view(keypoints)

        except Exception as e:
            logger.error(f"æºå¸¯ä½¿ç”¨åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def detect_phone_usage_back_view(self, keypoints):
        """èƒŒé¢ã‹ã‚‰ã®æºå¸¯ä½¿ç”¨æ¤œå‡ºï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            threshold = 60

            # å¿…è¦ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’å®‰å…¨ã«å–å¾—
            neck = self.safe_keypoint_access(keypoints, 1)
            left_wrist = self.safe_keypoint_access(keypoints, 9)
            right_wrist = self.safe_keypoint_access(keypoints, 10)
            left_shoulder = self.safe_keypoint_access(keypoints, 5)
            right_shoulder = self.safe_keypoint_access(keypoints, 6)

            # å…¨ã¦ã®ãƒã‚¤ãƒ³ãƒˆãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
            points = [neck, left_wrist, right_wrist, left_shoulder, right_shoulder]
            if any(pt is None for pt in points):
                return False

            # è·é›¢è¨ˆç®—
            dist_left = min(
                np.linalg.norm(left_wrist - neck),
                np.linalg.norm(left_wrist - left_shoulder)
            )
            dist_right = min(
                np.linalg.norm(right_wrist - neck),
                np.linalg.norm(right_wrist - right_shoulder)
            )

            return min(dist_left, dist_right) < threshold

        except Exception as e:
            logger.error(f"èƒŒé¢æºå¸¯ä½¿ç”¨æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def draw_monitor_grid(self, img, col_ratios, row_ratios):
        """ç›£è¦–ã‚°ãƒªãƒƒãƒ‰ã‚’æç”»"""
        h, w = img.shape[:2]
        # ç¸¦ç·š
        x_current = 0
        for ratio in col_ratios[:-1]:
            x_current += int(w * ratio)
            cv2.line(img, (x_current, 0), (x_current, h), (255, 255, 255), 2)
        # æ¨ªç·š
        y_current = 0
        for ratio in row_ratios[:-1]:
            y_current += int(h * ratio)
            cv2.line(img, (0, y_current), (w, y_current), (255, 255, 255), 2)

    def calculate_grid_boundaries(self, w, h, cols, rows):
        """ã‚°ãƒªãƒƒãƒ‰å¢ƒç•Œã‚’è¨ˆç®—"""
        x_grid = [0]
        for ratio in cols:
            x_grid.append(x_grid[-1] + int(w * ratio))
        y_grid = [0]
        for ratio in rows:
            y_grid.append(y_grid[-1] + int(h * ratio))
        return x_grid, y_grid

    def get_person_region(self, cx, cy, x_grid, y_grid):
        """äººç‰©ã®ä½ç½®ã™ã‚‹ã‚°ãƒªãƒƒãƒ‰é ˜åŸŸã‚’å–å¾—"""
        col_idx = row_idx = -1
        for i in range(len(x_grid) - 1):
            if x_grid[i] <= cx < x_grid[i + 1]:
                col_idx = i
                break
        for j in range(len(y_grid) - 1):
            if y_grid[j] <= cy < y_grid[j + 1]:
                row_idx = j
                break
        if col_idx == -1 or row_idx == -1:
            return None
        return row_idx, col_idx

    def process_frame(self, frame, frame_idx, csv_writer, enhanced_csv_logger=None):
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã—ã¦æ¤œå‡ºçµæœã‚’è¿”ã™ï¼ˆé †åºä»˜ãIDå‰²ã‚ŠæŒ¯ã‚Šç‰ˆ + æ‹¡å¼µCSVå¯¾å¿œï¼‰
        """
        height, width = frame.shape[:2]

        # YOLOæ¤œå‡ºå®Ÿè¡Œï¼ˆè¿½è·¡ãªã—ï¼‰
        try:
            results = self.model(frame, conf=self.config["conf_threshold"], verbose=False)
        except Exception as e:
            logger.error(f"YOLOæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return frame

        # ã‚°ãƒªãƒƒãƒ‰å¢ƒç•Œè¨ˆç®—
        x_grid, y_grid = self.calculate_grid_boundaries(
            width, height, self.split_ratios_cols, self.split_ratios
        )

        # æ¤œå‡ºçµæœã‚’æ•´ç†
        detections = []
        for result in results:
            if result.keypoints is None or result.boxes is None:
                continue

            try:
                kps_list = result.keypoints.xy.cpu().numpy()
                boxes = result.boxes.xyxy.cpu().numpy()
                confs = result.boxes.conf.cpu().numpy()

                for kps, box, conf in zip(kps_list, boxes, confs):
                    if conf < self.config["conf_threshold"]:
                        continue

                    if kps.shape[0] < 17:
                        continue

                    # ä¸­å¿ƒåº§æ¨™è¨ˆç®—
                    valid_points = kps[kps[:, 0] > 0]
                    if len(valid_points) == 0:
                        continue
                    center = np.mean(valid_points[:, :2], axis=0)
                    cx, cy = int(center[0]), int(center[1])

                    detections.append({
                        'center': (cx, cy),
                        'bbox': box,
                        'keypoints': kps,
                        'confidence': conf
                    })

            except Exception as e:
                logger.error(f"æ¤œå‡ºçµæœå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                continue

        # é †åºä»˜ãIDãƒˆãƒ©ãƒƒã‚«ãƒ¼ã§è¿½è·¡æ›´æ–°
        tracked_detections = self.id_tracker.update_tracks(detections)

        # ã‚°ãƒªãƒƒãƒ‰æç”»
        self.draw_monitor_grid(frame, self.split_ratios_cols, self.split_ratios)

        # æ¤œå‡ºçµæœã®æç”»
        for detection in tracked_detections:
            track_id = detection['track_id']
            kps = detection['keypoints']
            box = detection['bbox']
            cx, cy = detection['center']

            # æºå¸¯ä½¿ç”¨æ¤œå‡º
            using_phone = self.detect_phone_usage(kps)
            using_phone_raw = using_phone  # ç”Ÿã®åˆ¤å®šçµæœã‚’ä¿å­˜
            using_phone = self.smooth_detection(track_id, using_phone)

            # æ¤œå‡ºæ–¹æ³•ã®åˆ¤å®š
            phone_method = "front_view" if using_phone_raw else "back_view" if self.detect_phone_usage_back_view(kps) else "failed"
            phone_confidence = 0.8 if using_phone else 0.2  # ç°¡æ˜“çš„ãªä¿¡é ¼åº¦

            # é ˜åŸŸã®å–å¾—
            region = self.get_person_region(cx, cy, x_grid, y_grid)
            row, col = region if region else (-1, -1)

            # åŸºæœ¬CSVã«çµæœã‚’è¨˜éŒ²
            if csv_writer:
                csv_writer.writerow([frame_idx, track_id, using_phone, row, col])

            # æ‹¡å¼µCSVã«çµæœã‚’è¨˜éŒ²
            if enhanced_csv_logger is not None:
                try:
                    detection_data = {
                        'keypoints': kps,
                        'bbox': box,
                        'center': (cx, cy),
                        'confidence': detection['confidence']
                    }
                    enhanced_csv_logger.log_detection(
                        frame_idx=frame_idx,
                        track_id=track_id,
                        detection_data=detection_data,
                        frame=frame,
                        phone_usage=using_phone,
                        phone_confidence=phone_confidence,
                        phone_method=phone_method,
                        grid_row=row,
                        grid_col=col,
                        video_source="google_drive"
                    )
                except Exception as csv_error:
                    logger.error(f"æ‹¡å¼µCSVè¨˜éŒ²ã‚¨ãƒ©ãƒ¼ (frame={frame_idx}, person={track_id}): {csv_error}")


            # çŠ¶æ…‹è¡¨ç¤º
            if using_phone:
                color = (0, 0, 255)  # èµ¤è‰²
                label = f"ID: {track_id}: Phone"
            else:
                color = (255, 255, 0)  # é»„è‰²
                label = f"ID: {track_id}: Awake"

            if region:
                row, col = region
                label += f" [R{row},C{col}]"

            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
            x1, y1, x2, y2 = map(int, box)
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)
            cv2.putText(
                frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2
            )

            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»
            for pt in kps.astype(int):
                if len(pt) >= 2 and pt[0] > 0 and pt[1] > 0:
                    cv2.circle(frame, tuple(pt[:2]), 3, (255, 255, 0), -1)

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
        active_tracks = self.id_tracker.get_active_tracks()
        active_persons = len(active_tracks)

        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªIDã‚’å·¦ã‹ã‚‰é †ã«ã‚½ãƒ¼ãƒˆã—ã¦è¡¨ç¤º
        active_ids = sorted(active_tracks.keys())
        id_info = f"Active IDs (Lâ†’R): {active_ids}" if active_ids else "Active IDs: None"

        cv2.putText(
            frame,
            id_info,
            (20, height - 60),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0, 255, 0),
            2,
        )

        cv2.putText(
            frame,
            f"Total Persons: {active_persons}",
            (20, height - 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (0, 255, 0),
            2,
        )

        return frame


class IntegratedVideoProcessor:
    """çµ±åˆå‹•ç”»å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆé€†ãƒãƒ¬ãƒ«è£œæ­£ç‰ˆ + é †åºä»˜ãIDå‰²ã‚ŠæŒ¯ã‚Šï¼‰"""

    def __init__(self, k1=-0.1, strength=1.0, zoom_factor=0.8, model_path="yolo11m-pose.pt"):
        self.corrector = VideoDistortionCorrector(k1, strength, zoom_factor)
        self.detector = PostureDetectionSystem(model_path)

        # æ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        self.csv_logger = None

    def set_csv_logger(self, csv_path="enhanced_detection_log.csv"):
        """CSVãƒ­ã‚¬ãƒ¼ã‚’è¨­å®šï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            self.csv_logger = EnhancedCSVLogger(csv_path)
            logger.info(f"æ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–æˆåŠŸ: {csv_path}")
        except Exception as e:
            logger.error(f"æ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–å¤±æ•—: {e}")
            self.csv_logger = None

    def process_video(self, input_path, output_path, result_log="frame_results.csv",
                    show_preview=True, apply_correction=True):
        """
        å‹•ç”»ã‚’å‡¦ç†ï¼ˆé€†ãƒãƒ¬ãƒ«æ­ªã¿è£œæ­£ + å±…çœ ã‚Šæ¤œå‡º + é †åºä»˜ãIDå‰²ã‚ŠæŒ¯ã‚Šï¼‰

        Parameters:
        input_path: å…¥åŠ›å‹•ç”»ãƒ‘ã‚¹
        output_path: å‡ºåŠ›å‹•ç”»ãƒ‘ã‚¹
        result_log: çµæœãƒ­ã‚°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«å
        show_preview: ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã™ã‚‹ã‹
        apply_correction: æ­ªã¿è£œæ­£ã‚’é©ç”¨ã™ã‚‹ã‹
        """
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            logger.error(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {input_path}")
            return

        # å‹•ç”»æƒ…å ±å–å¾—
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        logger.info(f"å‹•ç”»æƒ…å ±: {width}x{height}, {fps:.1f}fps, {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ")

        # æ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼ã®çŠ¶æ…‹ç¢ºèª
        if self.csv_logger is not None:
            logger.info("æ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼ãŒæœ‰åŠ¹ã§ã™")
        else:
            logger.warning("æ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼ãŒç„¡åŠ¹ã§ã™")

        # æ­ªã¿è£œæ­£ãƒãƒƒãƒ—ä½œæˆ
        if apply_correction:
            logger.info("é€†ãƒãƒ¬ãƒ«æ­ªã¿è£œæ­£ï¼‹ã‚ºãƒ¼ãƒ èª¿æ•´ãƒãƒƒãƒ—ã‚’ä½œæˆä¸­...")
            self.corrector.create_correction_maps(width, height)
            logger.info(f"æ­ªã¿ä¿‚æ•°: {self.corrector.k1 * self.corrector.strength:.4f}")
            logger.info(f"ã‚ºãƒ¼ãƒ å€ç‡: {self.corrector.zoom_factor:.2f}x ({'å¼•ã' if self.corrector.zoom_factor < 1.0 else 'å¯„ã‚Š'})")

        # å‡ºåŠ›å‹•ç”»è¨­å®š
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        # çµæœãƒ­ã‚°æº–å‚™
        os.makedirs(os.path.dirname(result_log), exist_ok=True)

        detection_count = 0  # æ¤œå‡ºã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

        with open(result_log, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(["frame", "person_id", "using_phone", "grid_row", "grid_col"])

            frame_idx = 0
            start_time = time.time()

            logger.info("å‹•ç”»å‡¦ç†ã‚’é–‹å§‹... (å·¦ã‹ã‚‰é †IDå‰²ã‚ŠæŒ¯ã‚Šã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨)")

            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                frame_idx += 1

                # é€†ãƒãƒ¬ãƒ«æ­ªã¿è£œæ­£é©ç”¨
                if apply_correction:
                    frame = self.corrector.apply_correction(frame)

                # å±…çœ ã‚Šæ¤œå‡ºå‡¦ç†ï¼ˆæ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼ã‚’æ¸¡ã™ï¼‰
                try:
                    frame_before_detection = len(self.csv_logger.headers) if self.csv_logger else 0

                    frame = self.detector.process_frame(
                        frame, frame_idx, writer, self.csv_logger
                    )

                    # æ¤œå‡ºçµæœã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                    if self.csv_logger and hasattr(self.csv_logger, 'log_count'):
                        current_count = self.csv_logger.log_count
                        if current_count > detection_count:
                            detection_count = current_count

                except Exception as detection_error:
                    logger.error(f"ãƒ•ãƒ¬ãƒ¼ãƒ {frame_idx}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {detection_error}")

                # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·è¡¨ç¤º
                cv2.putText(
                    frame,
                    f"Frame: {frame_idx}/{total_frames}",
                    (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1,
                    (255, 255, 0),
                    2,
                )

                # æ‹¡å¼µCSVè¨˜éŒ²çŠ¶æ³è¡¨ç¤º
                if self.csv_logger and hasattr(self.csv_logger, 'log_count'):
                    cv2.putText(
                        frame,
                        f"Enhanced CSV: {self.csv_logger.log_count} records",
                        (20, 80),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 255, 255),
                        2,
                    )

                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                if show_preview:
                    display_title = "Integrated Video Processing (Fixed Enhanced CSV)"
                    cv2.imshow(display_title, frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        logger.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
                        break

                # çµæœä¿å­˜
                out.write(frame)

                # é€²è¡ŒçŠ¶æ³è¡¨ç¤º
                if frame_idx % 30 == 0:
                    elapsed = time.time() - start_time
                    fps_current = frame_idx / elapsed
                    progress = (frame_idx / total_frames) * 100
                    eta = (total_frames - frame_idx) / fps_current if fps_current > 0 else 0

                    active_tracks = self.detector.id_tracker.get_active_tracks()
                    csv_records = self.csv_logger.log_count if self.csv_logger else 0

                    logger.info(
                        f"é€²è¡ŒçŠ¶æ³: {progress:.1f}% ({frame_idx}/{total_frames}) "
                        f"å‡¦ç†é€Ÿåº¦: {fps_current:.1f}fps æ®‹ã‚Šæ™‚é–“: {eta:.1f}ç§’ "
                        f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ID: {sorted(active_tracks.keys())} "
                        f"æ‹¡å¼µCSVè¨˜éŒ²: {csv_records}è¡Œ"
                    )

        # ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
        cap.release()
        out.release()
        cv2.destroyAllWindows()

        # CSVãƒ­ã‚¬ãƒ¼ã‚’ã‚¯ãƒ­ãƒ¼ã‚º
        if self.csv_logger:
            self.csv_logger.close()

        # å‡¦ç†å®Œäº†æ™‚é–“
        total_time = time.time() - start_time
        logger.info(f"ğŸ‰ å‹•ç”»å‡¦ç†å®Œäº†!")
        logger.info(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
        logger.info(f"çµæœãƒ­ã‚°: {result_log}")
        logger.info(f"å‡¦ç†æ™‚é–“: {total_time:.1f}ç§’")
        logger.info(f"å¹³å‡å‡¦ç†é€Ÿåº¦: {frame_idx/total_time:.1f}fps")

        # æœ€çµ‚çµæœã®ç¢ºèª
        if self.csv_logger:
            final_records = self.csv_logger.log_count
            logger.info(f"æ‹¡å¼µCSVæœ€çµ‚è¨˜éŒ²æ•°: {final_records}è¡Œ")

            if final_records == 0:
                logger.warning("æ‹¡å¼µCSVã«ãƒ‡ãƒ¼ã‚¿ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
                logger.info("å¯èƒ½ãªåŸå› :")
                logger.info("  - äººç‰©ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸ")
                logger.info("  - ä¿¡é ¼åº¦é–¾å€¤ãŒé«˜ã™ãã‚‹")
                logger.info("  - ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºã«å¤±æ•—")
            else:
                logger.info(f"æ‹¡å¼µCSVã« {final_records}è¡Œã®ãƒ‡ãƒ¼ã‚¿ãŒè¨˜éŒ²ã•ã‚Œã¾ã—ãŸ")

        active_tracks = self.detector.id_tracker.get_active_tracks()
        logger.info(f"æœ€çµ‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ID: {sorted(active_tracks.keys())}")

    def process_image(self, image_path, output_dir="output", show_comparison=True):
        """
        ç”»åƒå‡¦ç†ï¼ˆé€†ãƒãƒ¬ãƒ«æ­ªã¿è£œæ­£ã®ã¿ï¼‰

        Parameters:
        image_path: å…¥åŠ›ç”»åƒãƒ‘ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        show_comparison: æ¯”è¼ƒè¡¨ç¤ºã™ã‚‹ã‹
        """
        # ç”»åƒèª­ã¿è¾¼ã¿
        image = cv2.imread(image_path)
        if image is None:
            logger.error(f"ç”»åƒãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“: {image_path}")
            return

        h, w = image.shape[:2]
        logger.info(f"ç”»åƒã‚’èª­ã¿è¾¼ã¿: {image_path}")
        logger.info(f"ç”»åƒã‚µã‚¤ã‚º: {w}x{h}")

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(output_dir, exist_ok=True)

        # é€†ãƒãƒ¬ãƒ«æ­ªã¿è£œæ­£ãƒãƒƒãƒ—ä½œæˆ
        self.corrector.create_correction_maps(w, h)

        # é€†ãƒãƒ¬ãƒ«æ­ªã¿è£œæ­£é©ç”¨
        logger.info(f"é€†ãƒãƒ¬ãƒ«æ­ªã¿è£œæ­£ï¼‹ã‚ºãƒ¼ãƒ èª¿æ•´ã‚’é©ç”¨ä¸­... (ã‚ºãƒ¼ãƒ : {self.corrector.zoom_factor:.2f}x)")
        corrected = self.corrector.apply_correction(image)

        # çµæœä¿å­˜
        output_path = os.path.join(output_dir, f'corrected_inverse_barrel_zoom_{self.corrector.zoom_factor:.2f}x.png')
        cv2.imwrite(output_path, corrected)
        logger.info(f"è£œæ­£å®Œäº†: {output_path}")

        # æ¯”è¼ƒè¡¨ç¤º
        if show_comparison:
            self._create_comparison_plot(image, corrected, output_dir)

        return corrected

    def _create_comparison_plot(self, original, corrected, output_dir):
        """æ¯”è¼ƒç”»åƒã‚’ä½œæˆ"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))

        # BGRâ†’RGBå¤‰æ›
        original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)
        corrected_rgb = cv2.cvtColor(corrected, cv2.COLOR_BGR2RGB)

        # ç”»åƒè¡¨ç¤º
        axes[0].imshow(original_rgb)
        axes[0].set_title('Original Image', fontsize=14)
        axes[0].axis('off')

        axes[1].imshow(corrected_rgb)
        axes[1].set_title(f'Inverse Barrel Corrected (Zoom: {self.corrector.zoom_factor:.2f}x)', fontsize=14)
        axes[1].axis('off')

        plt.tight_layout()
        # æ¯”è¼ƒç”»åƒä¿å­˜
        comparison_path = os.path.join(output_dir, f'comparison_inverse_barrel_zoom_{self.corrector.zoom_factor:.2f}x.png')
        plt.savefig(comparison_path, dpi=150, bbox_inches='tight')
        plt.show()

        logger.info(f"æ¯”è¼ƒç”»åƒã‚’ä¿å­˜: {comparison_path}")