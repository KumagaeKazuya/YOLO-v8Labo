class OrderedIDTracker:
    """å·¦ã‹ã‚‰é †ã«IDã‚’å‰²ã‚ŠæŒ¯ã‚‹è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆYOLOv11ã®trackæ©Ÿèƒ½ã¨ä½µç”¨ï¼‰"""

    def __init__(self, distance_threshold=100, max_missing_frames=30):
        self.distance_threshold = distance_threshold
        self.max_missing_frames = max_missing_frames
        self.tracked_persons = {}
        self.next_id = 1

    def get_active_tracks(self):
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªè¿½è·¡å¯¾è±¡ã‚’å–å¾—"""
        return {tid: data for tid, data in self.tracked_persons.items()}


class IntegratedVideoProcessor:
    """çµ±åˆå‹•ç”»å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆYOLOv11ç‰ˆï¼‰"""

    def __init__(self, k1=-0.1, k2=0.0, p1=0.0, p2=0.0, k3=0.0, alpha=0.6, focal_scale=0.9, strength=1.0, zoom_factor=0.8, model_path="yolov11n-pose.pt"):
        # æ”¹è‰¯ã•ã‚ŒãŸæ­ªã¿è£œæ­£å™¨
        self.corrector = VideoDistortionCorrector(k1, k2, p1, p2, k3, alpha, focal_scale, strength, zoom_factor)
        
        # YOLOv11ç‰ˆå§¿å‹¢æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
        self.detector = AdvancedPostureDetectionSystem(model_path)

        # æ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼
        self.csv_logger = None

        logger.info("YOLOv11çµ±åˆå‹•ç”»å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

    def set_csv_logger(self, csv_path="enhanced_detection_log.csv"):
        """CSVãƒ­ã‚¬ãƒ¼ã‚’è¨­å®š"""
        try:
            self.csv_logger = EnhancedCSVLogger(csv_path)
            logger.info(f"æ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–æˆåŠŸ: {csv_path}")
        except Exception as e:
            logger.error(f"æ‹¡å¼µCSVãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–å¤±æ•—: {e}")
            self.csv_logger = None

    def process_video(self, input_path, output_path, result_log="frame_results.csv",
                     show_preview=True, apply_correction=True):
        """
        å‹•ç”»ã‚’å‡¦ç†ï¼ˆYOLOv11ç‰ˆï¼‰

        Parameters:
        input_path: å…¥åŠ›å‹•ç”»ãƒ‘ã‚¹
        output_path: å‡ºåŠ›å‹•ç”»ãƒ‘ã‚¹
        result_log: çµæœãƒ­ã‚°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«å
        show_preview: ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã™ã‚‹ã‹
        apply_correction: æ­ªã¿è£œæ­£ã‚’é©ç”¨ã™ã‚‹ã‹
        """
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            logger.error(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {input_path}")
            return

        # å‹•ç”»æƒ…å ±å–å¾—
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        logger.info(f"å‹•ç”»æƒ…å ±: {width}x{height}, {fps:.1f}fps, {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ")

        # æ­ªã¿è£œæ­£ãƒãƒƒãƒ—ä½œæˆ
        if apply_correction:
            logger.info("æ”¹è‰¯ç‰ˆæ­ªã¿è£œæ­£ãƒãƒƒãƒ—ã‚’ä½œæˆä¸­...")
            self.corrector.create_correction_maps(width, height)

        # å‡ºåŠ›å‹•ç”»è¨­å®š
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        # çµæœãƒ­ã‚°æº–å‚™
        os.makedirs(os.path.dirname(result_log), exist_ok=True)

        all_results = []
        with open(result_log, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(["frame", "track_id", "phone_state", "grid_row", "grid_col"])

            frame_idx = 0
            start_time = time.time()

            logger.info("YOLOv11å‹•ç”»å‡¦ç†ã‚’é–‹å§‹...")

            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                frame_idx += 1

                # æ­ªã¿è£œæ­£é©ç”¨
                if apply_correction:
                    frame = self.corrector.apply_correction(frame)

                # YOLOv11å§¿å‹¢æ¤œå‡ºå‡¦ç†
                try:
                    processed_frame, frame_results = self.detector.process_frame(
                        frame, frame_idx, writer, self.csv_logger
                    )
                    all_results.extend(frame_results)

                except Exception as detection_error:
                    logger.error(f"ãƒ•ãƒ¬ãƒ¼ãƒ {frame_idx}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {detection_error}")
                    processed_frame = frame

                # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·è¡¨ç¤º
                cv2.putText(
                    processed_frame,
                    f"Frame: {frame_idx}/{total_frames} (YOLOv11)",
                    (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1,
                    (255, 255, 0),
                    2,
                )

                # æ‹¡å¼µCSVè¨˜éŒ²çŠ¶æ³è¡¨ç¤º
                if self.csv_logger and hasattr(self.csv_logger, 'log_count'):
                    cv2.putText(
                        processed_frame,
                        f"Enhanced CSV: {self.csv_logger.log_count} records",
                        (20, 80),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 255, 255),
                        2,
                    )

                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                if show_preview:
                    display_title = "YOLOv11 Integrated Video Processing"
                    cv2.imshow(display_title, processed_frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        logger.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
                        break

                # çµæœä¿å­˜
                out.write(processed_frame)

                # é€²è¡ŒçŠ¶æ³è¡¨ç¤º
                if frame_idx % 30 == 0:
                    elapsed = time.time() - start_time
                    fps_current = frame_idx / elapsed
                    progress = (frame_idx / total_frames) * 100
                    eta = (total_frames - frame_idx) / fps_current if fps_current > 0 else 0

                    csv_records = self.csv_logger.log_count if self.csv_logger else 0

                    logger.info(
                        f"é€²è¡ŒçŠ¶æ³: {progress:.1f}% ({frame_idx}/{total_frames}) "
                        f"å‡¦ç†é€Ÿåº¦: {fps_current:.1f}fps æ®‹ã‚Šæ™‚é–“: {eta:.1f}ç§’ "
                        f"æ¤œå‡ºæ•°: {len(frame_results)} "
                        f"æ‹¡å¼µCSVè¨˜éŒ²: {csv_records}è¡Œ"
                    )

        # ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
        cap.release()
        out.release()
        cv2.destroyAllWindows()

        # CSVãƒ­ã‚¬ãƒ¼ã‚’ã‚¯ãƒ­ãƒ¼ã‚º
        if self.csv_logger:
            self.csv_logger.close()

        # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
        if all_results:
            stats = self._get_statistics(all_results)
            logger.info("=== YOLOv11å‡¦ç†çµæœçµ±è¨ˆ ===")
            logger.info(f"ç·æ¤œå‡ºæ•°: {stats['total_detections']}")
            logger.info(f"å¹³å‡ä¿¡é ¼åº¦: {stats['average_confidence']:.3f}")
            logger.info(f"ã‚¹ãƒãƒ›ä½¿ç”¨ç‡: {stats['phone_usage_ratio']:.3f}")
            logger.info(f"çŠ¶æ…‹åˆ†å¸ƒ: {stats['state_distribution']}")
            logger.info(f"å‘ãåˆ†å¸ƒ: {stats['orientation_distribution']}")

        # å‡¦ç†å®Œäº†æ™‚é–“
        total_time = time.time() - start_time
        logger.info(f"ğŸ‰ YOLOv11å‹•ç”»å‡¦ç†å®Œäº†!")
        logger.info(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
        logger.info(f"çµæœãƒ­ã‚°: {result_log}")
        logger.info(f"å‡¦ç†æ™‚é–“: {total_time:.1f}ç§’")
        logger.info(f"å¹³å‡å‡¦ç†é€Ÿåº¦: {frame_idx/total_time:.1f}fps")

    def _get_statistics(self, results: List[DetectionResult]) -> Dict:
        """æ¤œå‡ºçµæœã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—"""
        if not results:
            return {}

        # çŠ¶æ…‹åˆ¥ã®çµ±è¨ˆ
        state_counts = defaultdict(int)
        orientation_counts = defaultdict(int)
        confidence_sum = 0

        for result in results:
            state_counts[result.phone_state.value] += 1
            orientation_counts[result.orientation.value] += 1
            confidence_sum += result.confidence

        # å¹³å‡ä¿¡é ¼åº¦
        avg_confidence = confidence_sum / len(results) if results else 0

        # ã‚¹ãƒãƒ›ä½¿ç”¨ç‡
        phone_usage_count = (
            state_counts['holding_near_face'] + 
            state_counts['looking_down'] + 
            state_counts['both_hands_up']
        )

        stats = {
            'total_detections': len(results),
            'average_confidence': avg_confidence,
            'state_distribution': dict(state_counts),
            'orientation_distribution': dict(orientation_counts),
            'phone_usage_ratio': phone_usage_count / len(results) if results else 0
        }

        return stats

    def process_image(self, image_path, output_dir="output", show_comparison=True):
        """
        ç”»åƒå‡¦ç†ï¼ˆæ”¹è‰¯ç‰ˆæ­ªã¿è£œæ­£ï¼‰

        Parameters:
        image_path: å…¥åŠ›ç”»åƒãƒ‘ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        show_comparison: æ¯”è¼ƒè¡¨ç¤ºã™ã‚‹ã‹
        """
        # ç”»åƒèª­ã¿è¾¼ã¿
        image = cv2.imread(image_path)
        if image is None:
            logger.error(f"ç”»åƒãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“: {image_path}")
            return

        h, w = image.shape[:2]
        logger.info(f"ç”»åƒã‚’èª­ã¿è¾¼ã¿: {image_path}")
        logger.info(f"ç”»åƒã‚µã‚¤ã‚º: {w}x{h}")

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(output_dir, exist_ok=True)

        # æ”¹è‰¯ç‰ˆæ­ªã¿è£œæ­£ãƒãƒƒãƒ—ä½œæˆ
        self.corrector.create_correction_maps(w, h)

        # æ­ªã¿è£œæ­£é©ç”¨
        logger.info(f"æ”¹è‰¯ç‰ˆæ­ªã¿è£œæ­£ã‚’é©ç”¨ä¸­...")
        corrected = self.corrector.apply_correction(image)

        # çµæœä¿å­˜
        output_path = os.path.join(output_dir, f'corrected_yolov11_enhanced.png')
        cv2.imwrite(output_path, corrected)
        logger.info(f"è£œæ­£å®Œäº†: {output_path}")

        # æ¯”è¼ƒè¡¨ç¤º
        if show_comparison:
            self._create_comparison_plot(image, corrected, output_dir)

        return corrected

    def _create_comparison_plot(self, original, corrected, output_dir):
        """æ¯”è¼ƒç”»åƒã‚’ä½œæˆ"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))

        # BGRâ†’RGBå¤‰æ›
        original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)
        corrected_rgb = cv2.cvtColor(corrected, cv2.COLOR_BGR2RGB)

        # ç”»åƒè¡¨ç¤º
        axes[0].imshow(original_rgb)
        axes[0].set_title('Original Image', fontsize=14)
        axes[0].axis('off')

        axes[1].imshow(corrected_rgb)
        axes[1].set_title(f'Enhanced Distortion Corrected (YOLOv11)', fontsize=14)
        axes[1].axis('off')

        plt.tight_layout()
        # æ¯”è¼ƒç”»åƒä¿å­˜
        comparison_path = os.path.join(output_dir, f'comparison_yolov11_enhanced.png')
        plt.savefig(comparison_path, dpi=150, bbox_inches='tight')
        plt.show()

        logger.info(f"æ¯”è¼ƒç”»åƒã‚’ä¿å­˜: {comparison_path}")